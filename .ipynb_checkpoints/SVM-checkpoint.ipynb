{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Direct Feature Extraction from Images\n",
    "Feature Extraction:\n",
    "\n",
    "Direct: The features are extracted directly from the raw image data using a simple CNN model defined in the code.\n",
    "Method: A custom CNN model (SimpleCNN) is used to extract features from the images. This model consists of three convolutional layers followed by max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = './trainingData'\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Extract features from images\n",
    "def extract_features_from_loader(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            outputs = model(inputs)\n",
    "            features.extend(outputs.cpu().numpy())\n",
    "            labels.extend(targets.cpu().numpy())\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Define a simple feature extraction model\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy using SVM: 0.8800\n",
      "Test Accuracy using SVM: 0.8681\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature extractor\n",
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Extract features for training data\n",
    "train_features, train_labels = extract_features_from_loader(train_dataloader, feature_extractor)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Extract features for validation data\n",
    "val_features, val_labels = extract_features_from_loader(val_dataloader, feature_extractor)\n",
    "\n",
    "# Predict and compute accuracy for validation data\n",
    "val_predictions = svm_classifier.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f'Validation Accuracy using SVM: {val_accuracy:.4f}')\n",
    "\n",
    "# Extract features for test data\n",
    "test_features, test_labels = extract_features_from_loader(test_dataloader, feature_extractor)\n",
    "\n",
    "# Predict and compute accuracy for test data\n",
    "test_predictions = svm_classifier.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f'Test Accuracy using SVM: {test_accuracy:.4f}')\n",
    "\n",
    "# Validation Accuracy using SVM: 0.9015\n",
    "# Test Accuracy using SVM: 0.9356\n",
    "# in 2 minutes\n",
    "\n",
    "# Validation Accuracy using SVM: 0.8800\n",
    "# Test Accuracy using SVM: 0.8681\n",
    "# in 1 min 46 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Connection to simple_cnn.pth\n",
    "Feature Extraction:\n",
    "\n",
    "Direct: Features are extracted indirectly from the images using a pre-trained CNN model saved in simple_cnn.pth.\n",
    "Method: The saved simple_cnn.pth file contains the trained weights of a CNN model. These weights are loaded into the SimpleCNN model used for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = './trainingData'\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, 3, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(16, 32, 3, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(32, 64, 3, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Flatten(),\n",
    ")\n",
    "\n",
    "# Load the pre-trained state dictionary\n",
    "state_dict = torch.load('simple_cnn.pth')\n",
    "\n",
    "# Remove keys corresponding to fully connected layers\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "# Extract features from images using the pre-trained CNN model\n",
    "def extract_features_from_loader(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            outputs = model(inputs)\n",
    "            features.extend(outputs.cpu().numpy())\n",
    "            labels.extend(targets.cpu().numpy())\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training data\n",
    "train_features, train_labels = extract_features_from_loader(train_dataloader, model)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Extract features from validation data\n",
    "val_features, val_labels = extract_features_from_loader(val_dataloader, model)\n",
    "\n",
    "# Predict and compute accuracy for validation data\n",
    "val_predictions = svm_classifier.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "print(f'Validation Accuracy using SVM: {val_accuracy:.4f}')\n",
    "\n",
    "# Extract features from test data\n",
    "test_features, test_labels = extract_features_from_loader(test_dataloader, model)\n",
    "\n",
    "# Predict and compute accuracy for test data\n",
    "test_predictions = svm_classifier.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f'Test Accuracy using SVM: {test_accuracy:.4f}')\n",
    "\n",
    "# Validation Accuracy using SVM: 0.9169\n",
    "# Test Accuracy using SVM: 0.8988\n",
    "# in 1 min 57 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad code with Validation \n",
    "# Accuracy using SVM: 0.2031\n",
    "# Test Accuracy using SVM: 0.2270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy using SVM: 0.2031\n",
      "Test Accuracy using SVM: 0.2270\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # Define transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load dataset\n",
    "# dataset_path = './trainingData'\n",
    "# dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# # Split dataset into training, validation, and test sets\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = int(0.1 * len(dataset))\n",
    "# test_size = len(dataset) - train_size - val_size\n",
    "# train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # # Define SimpleCNN model\n",
    "# class SimpleCNN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "#         self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "#         self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "#         self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "#         self.fc1 = torch.nn.Linear(64 * 28 * 28, 128)\n",
    "#         self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Initialize the SimpleCNN model\n",
    "# model = SimpleCNN()\n",
    "\n",
    "# # Load the pre-trained state dictionary\n",
    "# state_dict = torch.load('simple_cnn.pth')\n",
    "\n",
    "# # Remove keys corresponding to fully connected layers\n",
    "# state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
    "\n",
    "# # Load the state dictionary into the SimpleCNN model\n",
    "# model.load_state_dict(state_dict, strict=False)\n",
    "# model.eval()\n",
    "\n",
    "# # Extract features from images using the pre-trained CNN model\n",
    "# def extract_features_from_loader(loader, model):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in loader:\n",
    "#             outputs = model(inputs)\n",
    "#             features.extend(outputs.cpu().numpy())\n",
    "#             labels.extend(targets.cpu().numpy())\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Extract features from training data\n",
    "# train_features, train_labels = extract_features_from_loader(train_dataloader, model)\n",
    "\n",
    "# # Train SVM classifier\n",
    "# svm_classifier = SVC(kernel='linear')\n",
    "# svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# # Extract features from validation data\n",
    "# val_features, val_labels = extract_features_from_loader(val_dataloader, model)\n",
    "\n",
    "# # Predict and compute accuracy for validation data\n",
    "# val_predictions = svm_classifier.predict(val_features)\n",
    "# val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "# print(f'Validation Accuracy using SVM: {val_accuracy:.4f}')\n",
    "\n",
    "# # Extract features from test data\n",
    "# test_features, test_labels = extract_features_from_loader(test_dataloader, model)\n",
    "\n",
    "# # Predict and compute accuracy for test data\n",
    "# test_predictions = svm_classifier.predict(test_features)\n",
    "# test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "# print(f'Test Accuracy using SVM: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
